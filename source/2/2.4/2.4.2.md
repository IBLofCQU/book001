# 强化学习理论基础

&ensp;&ensp;&ensp;&ensp;
强化学习是机器学习的重要分支，主要用于解决序列决策（Sequential Decision）问题。在强化学习中，智能体与环境交互的过程可以用马尔科夫决策过程（Markov decision process，MDP）进行建模。马尔科夫决策过程是序列决策过程的数学模型，一般用于具备马尔科夫性的环境中，是智能推荐、强化学习、自动化控制、资源管理的基础理论框架。我们下面将按照逻辑顺序，对马尔科夫决策过程的理论基础进行介绍。

1. 马尔科夫性（Markov Property）和状态转移概率矩阵（State Transition Probability Matrix）

&ensp;&ensp;&ensp;&ensp;
在离散马尔可夫链中，智能体的所有状态向其它状态转移的概率可以组成一个状态转移概率矩阵P，简称转移矩阵。马尔科夫性指的是若未来的状态仅与当前的状态有关，与其他时刻的状态独立，即转化到未来下一时刻的状态St+1的概率仅与当前时刻的状态St有关，与之前的状态无关，用状态转移的概率公式表述如下：

$$

P[S_{t+1}|S_t]=P[S_{t+1}|S_1,...,S_t] \tag {2-52}

$$
